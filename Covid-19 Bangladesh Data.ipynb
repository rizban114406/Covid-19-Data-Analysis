{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featching Data From http://119.40.84.187/surveillance/ \n",
    "    Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['13/04/2020', '182'], ['12/04/2020', '139'], ['11/04/2020', '58'], ['10/04/2020', '94'], ['09/04/2020', '112'], ['08/04/2020', '54'], ['07/04/2020', '41'], ['06/04/2020', '35'], ['05/04/2020', '18'], ['04/04/2020', '9'], ['03/04/2020', '5'], ['02/04/2020', '2'], ['01/04/2020', '3'], ['31/03/2020', '2'], ['30/03/2020', '1'], ['29/03/2020', '0'], ['28/03/2020', '0'], ['27/03/2020', '4'], ['26/03/2020', '5'], ['25/03/2020', '0'], ['24/03/2020', '6'], ['23/03/2020', '6'], ['22/03/2020', '3'], ['21/03/2020', '4'], ['20/03/2020', '3'], ['19/03/2020', '3'], ['18/03/2020', '4'], ['17/03/2020', '2'], ['16/03/2020', '3'], ['15/03/2020', '2'], ['14/03/2020', '0'], ['13/03/2020', '0'], ['12/03/2020', '0'], ['11/03/2020', '0'], ['10/03/2020', '0'], ['09/03/2020', '0'], ['08/03/2020', '3']]\n",
      "[['<10', '17'], ['11-20', '46'], ['21-30', '122'], ['31-40', '143'], ['41-50', '115'], ['51-60', '95'], ['>60', '83']]\n",
      "[['UnderTreatment', '548'], ['Cured', '39'], ['Dead', '34']]\n",
      "[['Female', '187'], ['Male', '434']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import psutil,os\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "main_url='http://119.40.84.187/surveillance/'\n",
    "source = urllib.request.urlopen(main_url).read()\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "script=soup.find_all('script')\n",
    "# print(script)\n",
    "\n",
    "scrappedLines = []\n",
    "for lines in script:\n",
    "    data = (str(lines)).replace('\\r','')\n",
    "#     data = (str(data)).replace(' ','')\n",
    "    scrappedLines.append(data)\n",
    "# print(scrappedLines)\n",
    "# print(len(scrappedLines))\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"scrap.txt\", 'w+')\n",
    "for lines in scrappedLines:\n",
    "#     print(lines)\n",
    "#     print(\"bbbbbbbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "    if \"['Date', 'Number of Patients'],\" in lines:\n",
    "        data = (str(lines)).replace(' ','')\n",
    "        file.write(data)\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "file = open('scrap.txt','r')\n",
    "template = file.readlines()\n",
    "file.close()\n",
    "while '\\n' in template: template.remove('\\n')\n",
    "#print(len(template))\n",
    "#print(template)\n",
    "\n",
    "index = -1\n",
    "dataFlag = 0\n",
    "\n",
    "dateNumberofPatient = []\n",
    "agegroupNumber = []\n",
    "historyNumber = []\n",
    "genderNumber = []\n",
    "while(index < len(template)-1):\n",
    "    index = index + 1\n",
    "    template[index] = (template[index]).replace('\\n','')\n",
    "#     print(template[index])\n",
    "#     print(dataFlag)\n",
    "#    print(\"bbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "# Initialize Flag\n",
    "    if \"['Date','NumberofPatients'],\" in template[index]:\n",
    "        dataFlag = 1\n",
    "        continue\n",
    "    elif \"['AgeGroup','NumberofPatients'],\" in template[index]:\n",
    "        dataFlag = 2\n",
    "        continue\n",
    "    elif \"['History','NoofCase',{role:'style'}],\" in template[index]:\n",
    "        dataFlag = 3\n",
    "        continue\n",
    "    elif \"['Gender','NoofCase',{role:'style'}],\" in template[index]:\n",
    "        dataFlag = 4\n",
    "        continue\n",
    "\n",
    "# Fetching the Data \n",
    "    if dataFlag == 1:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            entryDate = splitLine[0][2:-1]\n",
    "            number = splitLine[1][:-1]\n",
    "            dateNumberofPatient.append([entryDate,number])\n",
    "            continue\n",
    "    if dataFlag == 2:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            ageGroup = splitLine[0][2:-1]\n",
    "            number = splitLine[1][:-1]\n",
    "            agegroupNumber.append([ageGroup,number])\n",
    "            continue\n",
    "    if dataFlag == 3:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            history = splitLine[0][2:-1]\n",
    "            number = splitLine[1]\n",
    "            historyNumber.append([history,number])\n",
    "            continue\n",
    "    if dataFlag == 4:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            gender = splitLine[0][2:-1]\n",
    "            number = splitLine[1]\n",
    "            genderNumber.append([gender,number])\n",
    "            continue\n",
    "#     print(\"bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "print(dateNumberofPatient)\n",
    "print(agegroupNumber)\n",
    "print(historyNumber)\n",
    "print(genderNumber)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featching Data From http://119.40.84.187/surveillance/ \n",
    "    Per Day Case\n",
    "    Age Group Distribution\n",
    "    Corona-Recovered-Death percentage\n",
    "    Gender Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "csv created.Check the location of this script \n",
      "csv file name: caseBangladesh.csv,coronaSituationBd.csv,ageRangeCaseBangladesh.csv.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import psutil,os\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "main_url='http://119.40.84.187/surveillance/'\n",
    "source = urllib.request.urlopen(main_url).read()\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "script=soup.find_all('script')\n",
    "\n",
    "\n",
    "scrappedLines = []\n",
    "for lines in script:\n",
    "    data = (str(lines)).replace('\\r','')\n",
    "# data = (str(data)).replace(' ','')\n",
    "    scrappedLines.append(data)\n",
    "# print(scrappedLines)\n",
    "# print(len(scrappedLines))\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"scrap.txt\", 'w+')\n",
    "for lines in scrappedLines:\n",
    "#     print(lines)\n",
    "#     print(\"bbbbbbbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "    if \"['Date', 'Number of Patients'],\" in lines:\n",
    "        data = (str(lines)).replace(' ','')\n",
    "        file.write(data)\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "file = open('scrap.txt','r')\n",
    "template = file.readlines()\n",
    "file.close()\n",
    "\n",
    "while '\\n' in template: template.remove('\\n')\n",
    "#print(len(template))\n",
    "#print(template)\n",
    "\n",
    "index = -1\n",
    "dataFlag = 0\n",
    "\n",
    "dateNumberofPatient = []\n",
    "agegroupNumber = []\n",
    "historyNumber = []\n",
    "genderNumber = []\n",
    "while(index < len(template)-1):\n",
    "    index = index + 1\n",
    "    template[index] = (template[index]).replace('\\n','')\n",
    "#    print(template[index])\n",
    "#    print(dataFlag)\n",
    "#    print(\"bbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "# Initialize Flag\n",
    "    if \"['Date','NumberofPatients'],\" in template[index]:\n",
    "        dataFlag = 1\n",
    "        continue\n",
    "    elif \"['AgeGroup','NumberofPatients'],\" in template[index]:\n",
    "        dataFlag = 2\n",
    "        continue\n",
    "    elif \"['History','NoofCase',{role:'style'}],\" in template[index]:\n",
    "        dataFlag = 3\n",
    "        continue\n",
    "    elif \"['Gender','NoofCase',{role:'style'}],\" in template[index]:\n",
    "        dataFlag = 4\n",
    "        continue\n",
    "\n",
    "# Fetching the Data \n",
    "    if dataFlag == 1:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            entryDate = splitLine[0][2:-1]\n",
    "            number = splitLine[1][:-1]\n",
    "            dateNumberofPatient.append([entryDate,number])\n",
    "            continue\n",
    "    if dataFlag == 2:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            ageGroup = splitLine[0][2:-1]\n",
    "            number = splitLine[1][:-1]\n",
    "            agegroupNumber.append([ageGroup,number])\n",
    "            continue\n",
    "    if dataFlag == 3:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            history = splitLine[0][2:-1]\n",
    "            number = splitLine[1]\n",
    "            historyNumber.append([history,number])\n",
    "            continue\n",
    "    if dataFlag == 4:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            gender = splitLine[0][2:-1]\n",
    "            number = splitLine[1]\n",
    "            genderNumber.append([gender,number])\n",
    "            continue\n",
    "\n",
    "    \n",
    "#    print(\"bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "\n",
    "\n",
    "#Making dataframe for (date & case), Giving column name,Making csv file\n",
    "\n",
    "dateNumberofPatient= pd.DataFrame(dateNumberofPatient)\n",
    "dateNumberofPatient.columns = ['date', 'case']\n",
    "\n",
    "dateNumberofPatient.sort_index(ascending=False, inplace=True)\n",
    "noOfDay=dateNumberofPatient.date.count() + 1\n",
    "day=[]\n",
    "for x in range(1,noOfDay):\n",
    "    day.append(x)\n",
    "dateNumberofPatient['day']=day\n",
    "dateNumberofPatient.to_csv(r'./Analysis Data/caseBangladesh.csv')\n",
    "\n",
    "print(noOfDay)\n",
    "\n",
    "\n",
    "    \n",
    "#Making dataframe for (ageRange & case), Giving column name,Making csv file\n",
    "\n",
    "agegroupNumber= pd.DataFrame(agegroupNumber)\n",
    "agegroupNumber.columns = ['ageRange', 'noOfCase']\n",
    "agegroupNumber.to_csv(r'./Analysis Data/ageRangeCaseBangladesh.csv')\n",
    "\n",
    "#Making dataframe for (ageRange & case), Giving column name,Making csv file\n",
    "\n",
    "historyNumber= pd.DataFrame(historyNumber)\n",
    "genderNumber= pd.DataFrame(genderNumber)\n",
    "coronaSituationBd = pd.concat([historyNumber, genderNumber])\n",
    "coronaSituationBd=coronaSituationBd.T\n",
    "coronaSituationBd.columns = [''] * len(coronaSituationBd.columns)\n",
    "coronaSituationBd.columns=coronaSituationBd.iloc[0]\n",
    "coronaSituationBd.drop(coronaSituationBd.index[0],inplace=True)\n",
    "coronaSituationBd.to_csv(r'./Analysis Data/coronaSituationBd.csv')\n",
    "\n",
    "print(\"csv created.Check the location of this script \")\n",
    "print(\"csv file name: caseBangladesh.csv,coronaSituationBd.csv,ageRangeCaseBangladesh.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featching Data From https://www.iedcr.gov.bd/ \n",
    "    Per Day Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import psutil,os\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "main_url='https://www.iedcr.gov.bd/'\n",
    "source = urllib.request.urlopen(main_url).read()\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "script=soup.find_all('script')\n",
    "# print(len(script))\n",
    "\n",
    "scrappedLines = []\n",
    "for lines in script:\n",
    "#     print(lines)\n",
    "    data = (str(lines)).replace('\\r','')\n",
    "# data = (str(data)).replace(' ','')\n",
    "    scrappedLines.append(data)\n",
    "# print(scrappedLines)\n",
    "# print(len(scrappedLines))\n",
    "\n",
    "\n",
    "\n",
    "file = open(\"scrap.txt\", 'w+')\n",
    "for lines in scrappedLines:\n",
    "#     print(lines)\n",
    "#     print(\"bbbbbbbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "    if \"Date wise COVID-19 Case\" in lines:\n",
    "#         print(lines)\n",
    "        data = (str(lines)).replace(' ','')\n",
    "        file.write(data)\n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "file = open('scrap.txt','r')\n",
    "template = file.readlines()\n",
    "file.close()\n",
    "\n",
    "while '\\n' in template: template.remove('\\n')\n",
    "#print(len(template))\n",
    "#print(template)\n",
    "\n",
    "index = -1\n",
    "dataFlag = 0\n",
    "\n",
    "dateNumberofPatient = []\n",
    "agegroupNumber = []\n",
    "historyNumber = []\n",
    "genderNumber = []\n",
    "while(index < len(template)-1):\n",
    "    index = index + 1\n",
    "    template[index] = (template[index]).replace('\\n','')\n",
    "#    print(template[index])\n",
    "#    print(dataFlag)\n",
    "#    print(\"bbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "# Initialize Flag\n",
    "    if \"Date\" in template[index] and \"Cases\" in template[index]:\n",
    "        dataFlag = 1\n",
    "        continue\n",
    "    elif \"['AgeGroup','NumberofPatients'],\" in template[index]:\n",
    "        dataFlag = 2\n",
    "        continue\n",
    "    elif \"['History','NoofCase',{role:'style'}],\" in template[index]:\n",
    "        dataFlag = 3\n",
    "        continue\n",
    "    elif \"['Gender','NoofCase',{role:'style'}],\" in template[index]:\n",
    "        dataFlag = 4\n",
    "        continue\n",
    "\n",
    "# Fetching the Data \n",
    "    if dataFlag == 1:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "#             print(splitLine[0])\n",
    "#             print(splitLine[1])\n",
    "            entryDate = splitLine[0][2:-1]\n",
    "#             print(entryDate)\n",
    "            number = splitLine[1]\n",
    "#             print(number)\n",
    "            dateNumberofPatient.append([entryDate,number])\n",
    "            continue\n",
    "    if dataFlag == 2:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            ageGroup = splitLine[0][2:-1]\n",
    "            number = splitLine[1][:-1]\n",
    "            agegroupNumber.append([ageGroup,number])\n",
    "            continue\n",
    "    if dataFlag == 3:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            history = splitLine[0][2:-1]\n",
    "            number = splitLine[1]\n",
    "            historyNumber.append([history,number])\n",
    "            continue\n",
    "    if dataFlag == 4:\n",
    "        if \"]);\" in template[index]:\n",
    "            dataFlag = 0\n",
    "            continue\n",
    "        else:           \n",
    "            splitLine = template[index].split(',')\n",
    "            gender = splitLine[0][2:-1]\n",
    "            number = splitLine[1]\n",
    "            genderNumber.append([gender,number])\n",
    "            continue\n",
    "\n",
    "    \n",
    "# #    print(\"bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\")\n",
    "\n",
    "\n",
    "# #Making dataframe for (date & case), Giving column name,Making csv file\n",
    "\n",
    "dateNumberofPatient= pd.DataFrame(dateNumberofPatient)\n",
    "dateNumberofPatient.columns = ['date', 'case']\n",
    "\n",
    "dateNumberofPatient.sort_index(ascending=True, inplace=True)\n",
    "noOfDay=dateNumberofPatient.date.count() + 1\n",
    "day=[]\n",
    "for x in range(1,noOfDay):\n",
    "    day.append(x)\n",
    "dateNumberofPatient['day']=day\n",
    "dateNumberofPatient.to_csv(r'./Analysis Data/covid-19-PerDayCaseBD.csv')\n",
    "\n",
    "print(noOfDay)\n",
    "\n",
    "\n",
    "    \n",
    "# #Making dataframe for (ageRange & case), Giving column name,Making csv file\n",
    "\n",
    "# agegroupNumber= pd.DataFrame(agegroupNumber)\n",
    "# agegroupNumber.columns = ['ageRange', 'noOfCase']\n",
    "# agegroupNumber.to_csv(r'./Analysis Data/ageRangeCaseBangladesh.csv')\n",
    "\n",
    "# #Making dataframe for (ageRange & case), Giving column name,Making csv file\n",
    "\n",
    "# historyNumber= pd.DataFrame(historyNumber)\n",
    "# genderNumber= pd.DataFrame(genderNumber)\n",
    "# coronaSituationBd = pd.concat([historyNumber, genderNumber])\n",
    "# coronaSituationBd=coronaSituationBd.T\n",
    "# coronaSituationBd.columns = [''] * len(coronaSituationBd.columns)\n",
    "# coronaSituationBd.columns=coronaSituationBd.iloc[0]\n",
    "# coronaSituationBd.drop(coronaSituationBd.index[0],inplace=True)\n",
    "# coronaSituationBd.to_csv(r'./Analysis Data/coronaSituationBd.csv')\n",
    "\n",
    "# print(\"csv created.Check the location of this script \")\n",
    "# print(\"csv file name: caseBangladesh.csv,coronaSituationBd.csv,ageRangeCaseBangladesh.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featching Data From https://www.iedcr.gov.bd/\n",
    "    Test Conducted 24 hour\n",
    "    Test Conducted Total\n",
    "    Case Positive 24 hour\n",
    "    Case Positive Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          0          1          2      3  \\\n",
      "0                     Updated on 16-04-2020  IEDCR lab  Other lab  Total   \n",
      "1  COVID-19 test conducted in last 24 hours        374       1761   2135   \n",
      "2             Total COVID-19 test conducted       4786      12217  17003   \n",
      "3  COVID-19 positive cases in last 24 hours         99        242    341   \n",
      "4                      COVID-19 Total cases        606        966   1572   \n",
      "\n",
      "   Updated On  \n",
      "0              \n",
      "1  2020-04-17  \n",
      "2  2020-04-17  \n",
      "3  2020-04-17  \n",
      "4  2020-04-17  \n",
      "CoronaTestCaseNo.csv created\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "main_url='https://www.iedcr.gov.bd/'\n",
    "source = urllib.request.urlopen(main_url).read()\n",
    "soup = bs.BeautifulSoup(source,'lxml')\n",
    "data = []\n",
    "table = soup.find('table')\n",
    "table_body = table.find('tbody')\n",
    "col=table.find_all('th')\n",
    "col = [ele.text.strip() for ele in col]\n",
    "data.append([ele for ele in col if ele])\n",
    "rows = table_body.find_all('tr')\n",
    "day=[]\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele])\n",
    "    \n",
    "testCaseNo= pd.DataFrame(data)\n",
    "testCaseNo['Updated On'] = ['',str(date.today()),str(date.today()),str(date.today()),str(date.today())]\n",
    "print(testCaseNo)\n",
    "\n",
    "testCaseNo.to_csv(r'./Analysis Data/covid-19-TestResultsBD.csv')\n",
    "print('CoronaTestCaseNo.csv created')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featching Data From https://www.iedcr.gov.bd/ \n",
    "    Division & District Wise Cases\n",
    "    Dhaka Area wise Covid-19 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "website/images/files/nCoV/Confirmed COVID-19 cases_upto_16_April 2020_last.pdf\n",
      "http://iedcr.gov.bd/website/images/files/nCoV/Confirmed%20COVID-19%20cases_upto_16_April%202020_last.pdf\n",
      "website/images/files/nCoV/COVID-19_Map_16_April.jpg\n",
      "website\n",
      "./downloads/2020-04-17.pdf\n",
      "./Analysis Data/covid-19-2020-04-17BD.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Apr 17, 2020 1:10:32 AM org.apache.pdfbox.pdmodel.font.PDCIDFontType2 <init>\r\n",
      "INFO: OpenType Layout tables used in font ABCDEE+Calibri are not implemented in PDFBox and will be ignored\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import re\n",
    "import psutil,os\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import os.path\n",
    "from os import path\n",
    "from datetime import date\n",
    "\n",
    "main_url='http://iedcr.gov.bd/'\n",
    "source = urllib.request.urlopen(main_url).read()\n",
    "# print(source)\n",
    "soup = bs.BeautifulSoup(source,'html.parser')\n",
    "# print(soup)\n",
    "script=soup.find_all('a',href = True)\n",
    "fileName = './downloads/' + str(date.today()) + '.pdf'\n",
    "fileNameCsv = './Analysis Data/covid-19-' + str(date.today()) + 'BD.csv'\n",
    "for links in soup.find_all('a',href = True):\n",
    "    print(links['href'])\n",
    "    if (len(links['href']) > 15 and len(links['href']) < 100 and ('.pdf' in str(links['href']))):\n",
    "        link = urllib.parse.quote(links['href'])\n",
    "        url = main_url + link\n",
    "#         url = \"https://iedcr.gov.bd/website/images/files/nCoV/Confirmed%20cases%20in%20Bangladesh_upto%20April%2012.pdf\"\n",
    "        print(url) \n",
    "        destination = str(fileName)\n",
    "        if path.exists(destination) == False:\n",
    "            print(\"New Downloading File: {}\".format(url))\n",
    "#             print(len(links['href']))\n",
    "            urllib.request.urlretrieve(url, destination)\n",
    "\n",
    "### Read pdf into list of DataFrame\n",
    "##df = tabula.read_pdf(\"2020-04-13.pdf\", pages='all')\n",
    "##\n",
    "### Read remote pdf into list of DataFrame\n",
    "##df2 = tabula.read_pdf(\"2020-04-13.pdf\")\n",
    "\n",
    "# convert PDF into CSV file\n",
    "print(fileName)\n",
    "print(fileNameCsv)\n",
    "tabula.convert_into(fileName, fileNameCsv, output_format=\"csv\", pages='all')\n",
    "\n",
    "# convert all PDFs in a directory\n",
    "##tabula.convert_into_by_batch(\"input_directory\", output_format='csv', pages='all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featching Data From https://www.iedcr.gov.bd/ (Alternative Way)\n",
    "    Division & District Wise Cases\n",
    "    Dhaka Area wise Covid-19 Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import psutil,os\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import os.path\n",
    "from os import path\n",
    "from datetime import date\n",
    "import requests\n",
    "\n",
    "main_url='http://iedcr.gov.bd/'\n",
    "source = urllib.request.urlopen(main_url).read()\n",
    "# print(source)\n",
    "soup = bs.BeautifulSoup(source,'html.parser')\n",
    "# print(soup)\n",
    "script=soup.find_all('a',href = True)\n",
    "for links in soup.find_all('a',href = True):\n",
    "    print(links['href'])\n",
    "    if (len(links['href']) > 15 and len(links['href']) < 100 and ('.pdf' in str(links['href']))):\n",
    "        link = urllib.parse.quote(links['href'])\n",
    "        url = main_url + link\n",
    "#         url = \"https://iedcr.gov.bd/website/images/files/nCoV/Confirmed%20cases%20in%20Bangladesh_upto%20April%2012.pdf\"\n",
    "        print(url)\n",
    "        fileName = './downloads/'+str(date.today()) + '.pdf'\n",
    "        myfile = requests.get(url)\n",
    "        open(fileName, 'wb').write(myfile.content)\n",
    "        print('downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a Specific File Using URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "print('Beginning file download with urllib2...')\n",
    "\n",
    "url = 'https://www.iedcr.gov.bd/website/images/files/nCoV/nCoV%20Press%20Release%2002022020.pdf'\n",
    "urllib.request.urlretrieve(url, './downloads/geee.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download All files from a URL Directory (https://www.iedcr.gov.bd/website/images/files/nCoV/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import psutil,os\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "main_url='https://www.iedcr.gov.bd/website/images/files/nCoV/'\n",
    "source = urllib.request.urlopen(main_url).read()\n",
    "# print(source)\n",
    "soup = bs.BeautifulSoup(source,'html.parser')\n",
    "# print(soup)\n",
    "script=soup.find_all('a',href = True)\n",
    "for links in soup.find_all('a',href = True):\n",
    "    if (len(links['href']) > 15 and len(links['href']) < 100 and ('.pdf' in str(links['href']))):\n",
    "        url = 'https://www.iedcr.gov.bd/website/images/files/nCoV/' + str(links['href'])\n",
    "        destination = './downloads/' + str(links['href'])\n",
    "        if path.exists(destination) == False:\n",
    "            print(\"New Downloading File: {}\".format(links['href']))\n",
    "#             print(len(links['href']))\n",
    "            urllib.request.urlretrieve(url, destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
